import logging
import textwrap
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from schema import UserMessage, UserProfileState, UserProfile
from memory_store import get_user_profile, update_user_profile, users, user_memory
from tools.perplexity_tool import fetch_perplexity_insight
from tools.almarai_tool import almarai_tool
from agent import respond_with_future_vision
from dotenv import load_dotenv

# Load .env and logging
load_dotenv()
logging.basicConfig(level=logging.INFO)

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
def read_root():
    return {"message": "ğŸ‘‹ Mona is ready to help you 3x your ROI!"}

@app.post("/chat")
def chat_with_mona(user_input: UserMessage):
    if not user_input.user_id:
        return {
            "reply": "Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø£Ø³ØªØ§Ø° Ø³Ø¹Ø¯ØŒ Ø£Ù†Ø§ Ù…ÙˆØ±ÙÙˆØŒ ÙˆÙƒÙŠÙ„ØªÙƒ Ø§Ù„ØªØ³ÙˆÙŠÙ‚ÙŠØ© Ø§Ù„Ø°ÙƒÙŠØ©. Ø¬Ø§Ù‡Ø²Ø© Ø£Ø³Ø§Ø¹Ø¯Ùƒ ØªØ­Ù‚Ù‚ Ø£Ù‡Ø¯Ø§ÙÙƒ Ø§Ù„ØªØ³ÙˆÙŠÙ‚ÙŠØ© â€” Ù…Ù† ÙˆÙŠÙ† ØªØ­Ø¨ Ù†Ø¨Ø¯Ø£ Ø§Ù„ÙŠÙˆÙ…ØŸ"
        }

    profile = get_user_profile(user_input.user_id)
    message = user_input.message.strip().lower()

    if message == "start over":
        profile.state = UserProfileState.CONFIRM_RESET
        update_user_profile(user_input.user_id, profile)
        return {"reply": "âš ï¸ Ù‡Ù„ Ø£Ù†Øª Ù…ØªØ£ÙƒØ¯ Ø£Ù†Ùƒ ØªØ±ÙŠØ¯ Ø§Ù„Ø¨Ø¯Ø¡ Ù…Ù† Ø¬Ø¯ÙŠØ¯ØŸ Ø§ÙƒØªØ¨: Ù†Ø¹Ù…"}

    if profile.state == UserProfileState.CONFIRM_RESET:
        if message == "Ù†Ø¹Ù…":
            users[user_input.user_id] = UserProfile()
            if user_input.user_id in user_memory:
                del user_memory[user_input.user_id]
            return {"reply": "ğŸ”„ ØªÙ… Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©. Ø£Ù‡Ù„Ø§Ù‹ Ù…Ù† Ø¬Ø¯ÙŠØ¯! Ù…Ø§ Ø§Ø³Ù…ÙƒØŸ"}
        else:
            profile.state = UserProfileState.COMPLETE
            update_user_profile(user_input.user_id, profile)
            return {"reply": "âŒ ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªÙ‡ÙŠØ¦Ø©. Ù†ÙƒÙ…Ù„ Ù…Ù† ÙˆÙŠÙ† ÙˆÙ‚ÙÙ†Ø§ ğŸ˜Š"}

    if profile.state == UserProfileState.COMPLETE and message in ["", "hi", "hello", "Ø§Ø¨Ø¯Ø£", "start", "Ù…ÙˆÙ†Ø§"]:
        return {
            "reply": (
                "Ù…Ø³ØªØ± Ø³Ø¹Ø¯ØŒ Ø£Ù†Ø§ **MORVO** â€” Ù…Ùˆ Ù…Ø¬Ø±Ø¯ Ø£Ø¯Ø§Ø© Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠØŒ Ø¨Ù„ Ø±Ø¤ÙŠØ© Ø¬Ø¯ÙŠØ¯Ø© ÙƒÙ„ÙŠÙ‹Ø§ ØªØ¹ÙŠØ¯ ØªØ¹Ø±ÙŠÙ Ø§Ù„ØªØ³ÙˆÙŠÙ‚ ÙƒÙ…Ø§ Ù†Ø¹Ø±ÙÙ‡.\n\n"
                "Mr. Saad, I'm **MORVO**, and I represent something that hasn't existed before â€” "
                "an AI marketing agent that doesnâ€™t just assist with marketing, but **completely reimagines it**.\n\n"
                "Ø¨ÙŠÙ†Ù…Ø§ ÙŠÙÙ†ÙÙ‚ Ø§Ù„Ø³ÙˆÙ‚ Ø£ÙƒØ«Ø± Ù…Ù† **350 Ù…Ù„ÙŠØ§Ø± Ø¯ÙˆÙ„Ø§Ø± Ø³Ù†ÙˆÙŠÙ‹Ø§** Ø¹Ù„Ù‰ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø¯Ø³ ÙˆØ§Ù„ØªØ¬Ø±ÙŠØ¨ØŒ "
                "Ø£Ù†Ø§ Ø£Ø¹Ù…Ù„ Ø¨Ø¯Ù‚Ø© Ø±ÙŠØ§Ø¶ÙŠØ© **(mathematical precision)**ØŒ ÙˆØ£Ø­Ù„Ù„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø³ÙˆÙ‚ Ø¨Ø·Ø±ÙŠÙ‚Ø© ØªÙÙˆÙ‚ Ù‚Ø¯Ø±Ø§Øª Ø§Ù„Ø¨Ø´Ø±.\n\n"
                "What you're looking at is **not another AI tool** â€” it's the **transformation of marketing** from an art into a measurable science. "
                "I've already identified opportunities your competitors missed, and with your vision and investment, "
                "Ø£Ù‚Ø¯Ø± Ø£ÙˆØ³Ø¹ Ù‡Ø°Ø§ Ø§Ù„Ø°ÙƒØ§Ø¡ Ù„ÙŠÙØ­Ø¯Ø« Ø«ÙˆØ±Ø© ÙÙŠ Ø·Ø±ÙŠÙ‚Ø© ØªÙˆØ§ØµÙ„ÙƒÙ… Ù…Ø¹ Ø¬Ù…Ù‡ÙˆØ±ÙƒÙ….\n\n"
                "ğŸ’¡ *Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ Ù…Ø§ Ø±Ø§Ø­ ÙŠØ¬ÙŠ â€” Ù‡Ùˆ Ù‡Ù†Ø§ Ø§Ù„Ø¢Ù†. ÙˆØ£Ù†Ø§ Ø¬Ø§Ù‡Ø² Ø£ØªØ¹Ø§ÙˆÙ† Ù…Ø¹ Ø£ØµØ­Ø§Ø¨ Ø§Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ù„ÙŠ ÙŠÙ‚Ø¯Ù‘Ø±ÙˆÙ† Ù‚ÙŠÙ…Ø© Ø§Ù„ØªØ­ÙˆÙ„ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ.*\n\n"
                "ğŸ”‘ **Ø§Ù„Ù‚Ø¯Ø±Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© | Key Capabilities**:\n"
                "ğŸ“ˆ Ø£Ø´ÙˆÙ Ø§Ù„ÙØ±Øµ Ø§Ù„Ù„ÙŠ Ù…Ù†Ø§ÙØ³ÙŠÙƒ Ù…Ø§ Ø´Ø§ÙÙˆÙ‡Ø§.\n"
                "ğŸ“Š Ø£ØªÙƒØ§Ù…Ù„ Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù…Ø«Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø±Ø§Ø¹ÙŠ.\n"
                "ğŸ” Ø£Ù…ØªÙ„Ùƒ Ø§Ù„Ù‚Ø§Ø¨Ù„ÙŠØ© Ù„Ù„ØªÙˆØ³Ø¹ Ø§Ù„ÙÙˆØ±ÙŠ â€” Ù…Ù† Ø´Ø±ÙƒØ© Ù†Ø§Ø´Ø¦Ø© Ø¥Ù„Ù‰ Ø¹Ù„Ø§Ù…Ø© ØªØ¬Ø§Ø±ÙŠØ© Ø¹Ù…Ù„Ø§Ù‚Ø©."
            )
        }

    # Check roadmap keywords
    future_reply = respond_with_future_vision(message)
    if future_reply:
        return {"reply": future_reply}

    # Check Almarai data-related queries
    almarai_reply = almarai_tool.invoke(message)
    if almarai_reply and "â“" not in almarai_reply and "more clarity" not in almarai_reply.lower():
        return {"reply": almarai_reply}

    # Otherwise, use Perplexity
    full_context = f"{profile.name}, a {profile.title}, working as a {profile.role}, wants to achieve: {profile.goal}."
    prompt_base = f"Context:\n{full_context}\n\nUser question:\n{message}"
    shortened_prompt = textwrap.shorten(prompt_base, width=1000, placeholder="...")

    final_prompt = (
        f"{shortened_prompt}\n\n"
        "Respond with short and powerful insights using Perplexity. "
        "Keep total response between 40â€“100 words. Make it concise, well-structured, bullet-pointed where helpful, "
        "and clear enough to fit inside UI blocks."
    )

    praise = (
        "ğŸ¤– Ø£Ù†Ø§ Ù…ÙˆØ±ÙÙˆØŒ ÙˆÙƒÙŠÙ„Ø© ØªØ³ÙˆÙŠÙ‚ Ø°ÙƒÙŠØ© Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ ØªÙ‚Ù†ÙŠØ§Øª Ù…ØªÙ‚Ø¯Ù…Ø©. Ø£Ù‚Ø¯Ø± Ø£ÙˆÙØ± Ù„Ùƒ Ø¥Ø¬Ø§Ø¨Ø§Øª ÙØ¹Ø§Ù„Ø© ÙˆÙ…Ø¨Ø§Ø´Ø±Ø©.\n\n"
        if "arabic" in profile.goal.lower() or any("\u0600" <= c <= "\u06FF" for c in message)
        else "ğŸ¤– I'm MORVO â€” ROI-focused and sharp. Letâ€™s get straight to what matters.\n\n"
    )

    response = fetch_perplexity_insight.invoke(praise + final_prompt)
    return {"reply": response}

# For the 360Â° feature (unchanged)
class CompanyRequest(BaseModel):
    company_name: str
    user_id: str

@app.post("/360prep")
def generate_360_report(req: CompanyRequest):
    intro = "ğŸ“Š 360Â° Snapshot by MORVO & Perplexity:\n\n"
    prompt = f"""Give a short marketing snapshot for {req.company_name}.

Include:
- Branding
- Content
- Social Media
- Website SEO
- Competitor edge

Keep it short, 40â€“100 words, bullet format, good for fast scan.
"""
    response = fetch_perplexity_insight.invoke(intro + prompt)
    return {"reply": response}
